import json
import os


def create_people_analytics_notebook(output_path="analyze_people_data.ipynb"):
    """
    Creates an enhanced Jupyter notebook for people analytics data analysis.

    Args:
        output_path (str): Path where the notebook should be saved
    """
    # Define notebook content
    notebook = {
        "cells": [
            {
                "cell_type": "markdown",
                "metadata": {},
                "source": [
                    "# üìä People Analytics Dashboard\n",
                    "\n",
                    "Este notebook interativo fornece an√°lises avan√ßadas e visualiza√ß√µes para os dados de avalia√ß√£o de desempenho.",
                ],
            },
            {
                "cell_type": "markdown",
                "metadata": {},
                "source": [
                    "## üîß Configura√ß√£o e Importa√ß√µes\n",
                    "Carregando as bibliotecas e configura√ß√µes necess√°rias para an√°lise avan√ßada.",
                ],
            },
            {
                "cell_type": "code",
                "execution_count": None,
                "metadata": {},
                "outputs": [],
                "source": [
                    "# Importa√ß√µes necess√°rias\n",
                    "import os\n",
                    "import json\n",
                    "import pandas as pd\n",
                    "import numpy as np\n",
                    "import matplotlib.pyplot as plt\n",
                    "import seaborn as sns\n",
                    "import plotly.express as px\n",
                    "import plotly.graph_objects as go\n",
                    "from plotly.subplots import make_subplots\n",
                    "from pathlib import Path\n",
                    "from collections import defaultdict\n",
                    "from IPython.display import display, HTML, Markdown\n",
                    "import warnings\n",
                    "\n",
                    "# Configura√ß√µes para melhor exibi√ß√£o\n",
                    "pd.set_option('display.max_columns', None)\n",
                    "pd.set_option('display.max_rows', 100)\n",
                    "pd.set_option('display.width', 1000)\n",
                    "pd.set_option('display.max_colwidth', None)\n",
                    'warnings.filterwarnings("ignore")\n',
                    "\n",
                    "# Configura√ß√£o de estilo para visualiza√ß√µes\n",
                    "plt.style.use('ggplot')\n",
                    'sns.set_theme(style="whitegrid")\n',
                    "\n",
                    "# Cores para visualiza√ß√µes\n",
                    "COLORS = px.colors.qualitative.Plotly\n",
                    "\n",
                    "# Estilo para HTML\n",
                    'HTML("""\n',
                    "<style>\n",
                    "    h1 { color: #2c3e50; }\n",
                    "    h2 { color: #34495e; border-bottom: 1px solid #95a5a6; padding-bottom: 5px; }\n",
                    "    h3 { color: #3498db; }\n",
                    "    .alert-success { background-color: #d4edda; color: #155724; padding: 15px; border-radius: 5px; }\n",
                    "    .alert-info { background-color: #d1ecf1; color: #0c5460; padding: 15px; border-radius: 5px; }\n",
                    "    .alert-warning { background-color: #fff3cd; color: #856404; padding: 15px; border-radius: 5px; }\n",
                    "    .alert-danger { background-color: #f8d7da; color: #721c24; padding: 15px; border-radius: 5px; }\n",
                    "    table { border-collapse: collapse; margin: 20px 0; }\n",
                    "    table th { background-color: #3498db; color: white; }\n",
                    "    table th, table td { padding: 10px; border: 1px solid #ddd; }\n",
                    "    table tr:nth-child(even) { background-color: #f2f2f2; }\n",
                    "</style>\n",
                    '""")',
                ],
            },
            {
                "cell_type": "markdown",
                "metadata": {},
                "source": [
                    "## üõ†Ô∏è Fun√ß√µes Utilit√°rias\n",
                    "Conjunto de fun√ß√µes para carregamento, processamento e an√°lise de dados.",
                ],
            },
            {
                "cell_type": "code",
                "execution_count": None,
                "metadata": {},
                "outputs": [],
                "source": [
                    "def load_json_file(file_path):\n",
                    '    """Carrega um arquivo JSON com tratamento de erros\n',
                    "    \n",
                    "    Args:\n",
                    "        file_path (str): Caminho para o arquivo JSON\n",
                    "        \n",
                    "    Returns:\n",
                    "        tuple: (dados JSON ou None se erro, mensagem de erro ou None se sucesso)\n",
                    '    """\n',
                    "    try:\n",
                    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
                    "            return json.load(f), None\n",
                    "    except json.JSONDecodeError as e:\n",
                    '        return None, f"Erro ao decodificar JSON: {str(e)}"\n',
                    "    except Exception as e:\n",
                    '        return None, f"Erro ao ler arquivo: {str(e)}"\n',
                    "\n",
                    'def scan_directory(directory_path, pattern="*/*/resultado.json"):\n',
                    '    """Escaneia diret√≥rio procurando arquivos que seguem um padr√£o\n',
                    "    \n",
                    "    Args:\n",
                    "        directory_path (str): Caminho do diret√≥rio a ser escaneado\n",
                    "        pattern (str): Padr√£o glob a ser procurado\n",
                    "        \n",
                    "    Returns:\n",
                    "        list: Lista de caminhos de arquivos encontrados\n",
                    '    """\n',
                    "    path = Path(directory_path)\n",
                    "    files = list(path.glob(pattern))\n",
                    "    return files\n",
                    "\n",
                    "def extract_person_year(file_path):\n",
                    '    """Extrai nome da pessoa e ano a partir do caminho do arquivo\n',
                    "    \n",
                    "    Args:\n",
                    "        file_path (Path): Caminho do arquivo\n",
                    "        \n",
                    "    Returns:\n",
                    "        tuple: (nome da pessoa, ano)\n",
                    '    """\n',
                    "    parts = file_path.parts\n",
                    "    person_idx = len(parts) - 3\n",
                    "    year_idx = len(parts) - 2\n",
                    "    \n",
                    "    if person_idx >= 0 and year_idx >= 0:\n",
                    "        return parts[person_idx], parts[year_idx]\n",
                    '    return "Unknown", "Unknown"\n',
                    "\n",
                    "def diagnose_json_file(file_path):\n",
                    '    """Diagnostica problemas em um arquivo JSON de avalia√ß√£o\n',
                    "    \n",
                    "    Args:\n",
                    "        file_path (str): Caminho para o arquivo JSON\n",
                    "        \n",
                    "    Returns:\n",
                    "        dict: Dicion√°rio com status da an√°lise e problemas encontrados\n",
                    '    """\n',
                    "    data, error = load_json_file(file_path)\n",
                    "    if error:\n",
                    '        return {"file": str(file_path), "status": "error", "message": error}\n',
                    "    \n",
                    "    issues = []\n",
                    "    \n",
                    "    # Verificar estrutura b√°sica\n",
                    "    if 'data' not in data:\n",
                    "        issues.append(\"Campo 'data' ausente\")\n",
                    "    elif 'direcionadores' not in data['data']:\n",
                    "        issues.append(\"Campo 'direcionadores' ausente\")\n",
                    "    elif not data['data']['direcionadores']:\n",
                    '        issues.append("Lista de direcionadores vazia")\n',
                    "    else:\n",
                    "        # Verificar cada direcionador e comportamento\n",
                    "        for i, direcionador in enumerate(data['data']['direcionadores']):\n",
                    "            if 'comportamentos' not in direcionador:\n",
                    "                issues.append(f\"Direcionador {i+1} n√£o tem campo 'comportamentos'\")\n",
                    "                continue\n",
                    "                \n",
                    "            for j, comportamento in enumerate(direcionador.get('comportamentos', [])):\n",
                    "                if 'avaliacoes_grupo' not in comportamento:\n",
                    "                    issues.append(f\"Comportamento {j+1} em Direcionador {i+1} n√£o tem campo 'avaliacoes_grupo'\")\n",
                    "                    continue\n",
                    "                    \n",
                    "                for k, avaliacao in enumerate(comportamento.get('avaliacoes_grupo', [])):\n",
                    "                    if 'frequencia_colaborador' not in avaliacao:\n",
                    "                        issues.append(f\"Avalia√ß√£o {k+1} em Comportamento {j+1} n√£o tem campo 'frequencia_colaborador'\")\n",
                    "                    elif not isinstance(avaliacao.get('frequencia_colaborador'), list):\n",
                    "                        issues.append(f\"Campo 'frequencia_colaborador' n√£o √© uma lista em Avalia√ß√£o {k+1}\")\n",
                    "                        \n",
                    "                    if 'frequencia_grupo' not in avaliacao:\n",
                    "                        issues.append(f\"Avalia√ß√£o {k+1} em Comportamento {j+1} n√£o tem campo 'frequencia_grupo'\")\n",
                    "                    elif not isinstance(avaliacao.get('frequencia_grupo'), list):\n",
                    "                        issues.append(f\"Campo 'frequencia_grupo' n√£o √© uma lista em Avalia√ß√£o {k+1}\")\n",
                    "    \n",
                    "    return {\n",
                    '        "file": str(file_path),\n',
                    '        "status": "ok" if not issues else "issues",\n',
                    '        "issues": issues,\n',
                    '        "data": data\n',
                    "    }\n",
                ],
            },
        ],
        "metadata": {
            "kernelspec": {
                "display_name": "Python 3",
                "language": "python",
                "name": "python3",
            },
            "language_info": {
                "codemirror_mode": {"name": "ipython", "version": 3},
                "file_extension": ".py",
                "mimetype": "text/x-python",
                "name": "python",
                "nbconvert_exporter": "python",
                "pygments_lexer": "ipython3",
                "version": "3.12.3",
            },
        },
        "nbformat": 4,
        "nbformat_minor": 4,
    }

    # Add data loading cells
    data_loading_cells = [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìÇ Carregamento dos Dados\n",
                "Configure o caminho para o diret√≥rio de dados e carregue as avalia√ß√µes.",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Configurar caminho para diret√≥rio de dados\n",
                'DATA_DIR = "data"  # Altere para o caminho dos seus dados reais\n',
                "\n",
                "# Encontrar arquivos no padr√£o <pessoa>/<ano>/resultado.json\n",
                'files = scan_directory(DATA_DIR, "*/*/resultado.json")\n',
                'print(f"Encontrados {len(files)} arquivos de resultados:")\n',
                "for f in files:\n",
                '    print(f"  - {f}")\n',
                "\n",
                "# Carregar todos os dados em um DataFrame\n",
                "df_evaluations = load_all_evaluations(DATA_DIR)\n",
                "\n",
                "if df_evaluations.empty:\n",
                "    display(HTML('<div class=\"alert-danger\">Nenhum dado de avalia√ß√£o encontrado. Verifique o caminho especificado.</div>'))\n",
                "else:\n",
                '    display(HTML(f\'<div class="alert-success">Carregados dados de {df_evaluations["pessoa"].nunique()} pessoas em {df_evaluations["ano"].nunique()} anos.</div>\'))\n',
                "    display(df_evaluations.head())",
            ],
        },
    ]

    # Add corrected analysis cells with proper interpretation
    corrected_analysis_cells = [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ‚ö†Ô∏è Corre√ß√£o na Interpreta√ß√£o dos Dados\n",
                "Os vetores de frequ√™ncia t√™m 6 posi√ß√µes com significados espec√≠ficos.",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "source": [
                "def convert_evaluation_to_dataframe(eval_data, person, year):\n",
                '    """Converte dados de avalia√ß√£o para um DataFrame pandas\n',
                "    \n",
                "    Args:\n",
                "        eval_data (dict): Dados de avalia√ß√£o\n",
                "        person (str): Nome da pessoa\n",
                "        year (str): Ano da avalia√ß√£o\n",
                "        \n",
                "    Returns:\n",
                "        pandas.DataFrame: DataFrame com os dados estruturados\n",
                '    """\n',
                "    rows = []\n",
                "    \n",
                "    # R√≥tulos para cada posi√ß√£o no vetor\n",
                '    position_labels = ["n√£o informado", "refer√™ncia", "acima do esperado", \n',
                '                      "dentro do esperado", "abaixo do esperado", "muito abaixo do esperado"]\n',
                "    \n",
                '    # Valores para c√°lculo do score (invertido para que "acima do esperado" tenha maior valor)\n',
                "    # N√£o informado recebe 0, refer√™ncia √© neutro, e os outros s√£o por escala de valor\n",
                "    position_values = [0, 2.5, 4, 3, 2, 1]\n",
                "    \n",
                "    try:\n",
                '        for direcionador in eval_data["data"]["direcionadores"]:\n',
                '            for comportamento in direcionador.get("comportamentos", []):\n',
                '                for avaliacao in comportamento.get("avaliacoes_grupo", []):\n',
                '                    freq_colab = avaliacao.get("frequencia_colaborador", [])\n',
                '                    freq_grupo = avaliacao.get("frequencia_grupo", [])\n',
                "                    \n",
                "                    # Verificar se temos vetores v√°lidos com 6 posi√ß√µes\n",
                "                    if len(freq_colab) != 6 or len(freq_grupo) != 6 or sum(freq_colab) == 0 or sum(freq_grupo) == 0:\n",
                "                        continue\n",
                "                    \n",
                "                    # Calcular scores ponderados pelos valores de cada posi√ß√£o\n",
                '                    # Exclu√≠mos "n√£o informado" do c√°lculo do total para n√£o distorcer\n',
                "                    total_colab = sum(freq_colab[1:]) # Excluindo posi√ß√£o 0 (n√£o informado)\n",
                "                    total_grupo = sum(freq_grupo[1:]) # Excluindo posi√ß√£o 0 (n√£o informado)\n",
                "                    \n",
                "                    if total_colab == 0 or total_grupo == 0:\n",
                "                        continue\n",
                "                    \n",
                "                    # C√°lculo do score ponderado\n",
                "                    score_colab = sum(v * position_values[i] for i, v in enumerate(freq_colab)) / total_colab\n",
                "                    score_grupo = sum(v * position_values[i] for i, v in enumerate(freq_grupo)) / total_grupo\n",
                "                    \n",
                "                    # Criar distribui√ß√£o percentual para visualiza√ß√£o\n",
                "                    dist_colab = [round(100 * v / sum(freq_colab), 1) if sum(freq_colab) > 0 else 0 for v in freq_colab]\n",
                "                    dist_grupo = [round(100 * v / sum(freq_grupo), 1) if sum(freq_grupo) > 0 else 0 for v in freq_grupo]\n",
                "                    \n",
                "                    row = {\n",
                '                        "pessoa": person,\n',
                '                        "ano": year,\n',
                '                        "direcionador": direcionador.get("direcionador", ""),\n',
                '                        "comportamento": comportamento.get("comportamento", ""),\n',
                '                        "avaliador": avaliacao.get("avaliador", ""),\n',
                '                        "score_colaborador": score_colab,\n',
                '                        "score_grupo": score_grupo,\n',
                '                        "diferenca": score_colab - score_grupo,\n',
                '                        "freq_colab_raw": freq_colab,\n',
                '                        "freq_grupo_raw": freq_grupo,\n',
                '                        "freq_colab_pct": dist_colab,\n',
                '                        "freq_grupo_pct": dist_grupo\n',
                "                    }\n",
                "                    rows.append(row)\n",
                "    except Exception as e:\n",
                '        print(f"Erro ao processar dados para {person}, {year}: {str(e)}")\n',
                "    \n",
                "    return pd.DataFrame(rows)\n",
                "\n",
                "def load_all_evaluations(data_dir):\n",
                '    """Carrega todas as avalia√ß√µes com interpreta√ß√£o correta dos vetores\n',
                "    \n",
                "    Args:\n",
                "        data_dir (str): Caminho do diret√≥rio com os dados\n",
                "        \n",
                "    Returns:\n",
                "        pandas.DataFrame: DataFrame consolidado com todos os dados\n",
                '    """\n',
                '    files = scan_directory(data_dir, "*/*/resultado.json")\n',
                "    all_data = []\n",
                "    \n",
                "    for file_path in files:\n",
                "        diagnosis = diagnose_json_file(file_path)\n",
                '        if diagnosis["status"] == "error" or diagnosis["status"] == "issues":\n',
                "            print(f\"Problemas com arquivo {file_path}: {diagnosis.get('message') or diagnosis.get('issues')}\")\n",
                "            continue\n",
                "            \n",
                "        person, year = extract_person_year(file_path)\n",
                '        df = convert_evaluation_to_dataframe(diagnosis["data"], person, year)\n',
                "        all_data.append(df)\n",
                "    \n",
                "    if not all_data:\n",
                "        return pd.DataFrame()\n",
                "        \n",
                "    return pd.concat(all_data, ignore_index=True)",
            ],
        },
    ]

    # Add visualization cells
    visualization_cells = [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìä Visualiza√ß√£o da Distribui√ß√£o de Frequ√™ncias\n",
                "An√°lise da distribui√ß√£o percentual em cada categoria de avalia√ß√£o.",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Definir r√≥tulos para visualiza√ß√£o\n",
                'position_labels = ["N√£o informado", "Refer√™ncia", "Acima do esperado", "Dentro do esperado", "Abaixo do esperado", "Muito abaixo do esperado"]\n',
                "\n",
                "if not df_evaluations.empty:\n",
                "    # Estat√≠sticas gerais\n",
                "    stats = {\n",
                '        "Quantidade de pessoas": df_evaluations["pessoa"].nunique(),\n',
                '        "Anos de avalia√ß√£o": sorted(df_evaluations["ano"].unique()),\n',
                '        "Direcionadores": df_evaluations["direcionador"].nunique(),\n',
                '        "Comportamentos": df_evaluations["comportamento"].nunique(),\n',
                '        "Tipos de avaliadores": df_evaluations["avaliador"].nunique(),\n',
                '        "Score m√©dio individual": df_evaluations["score_colaborador"].mean(),\n',
                '        "Score m√©dio grupo": df_evaluations["score_grupo"].mean(),\n',
                '        "Diferen√ßa m√©dia": df_evaluations["diferenca"].mean()\n',
                "    }\n",
                "    \n",
                "    # Exibir estat√≠sticas em uma tabela HTML formatada\n",
                '    html_stats = "<table>"\n',
                '    html_stats += "<tr><th>M√©trica</th><th>Valor</th></tr>"\n',
                "    for key, value in stats.items():\n",
                "        if isinstance(value, float):\n",
                '            value_str = f"{value:.2f}"\n',
                "        elif isinstance(value, list):\n",
                '            value_str = ", ".join(str(v) for v in value)\n',
                "        else:\n",
                "            value_str = str(value)\n",
                '        html_stats += f"<tr><td>{key}</td><td>{value_str}</td></tr>"\n',
                '    html_stats += "</table>"\n',
                "    \n",
                "    display(HTML(html_stats))\n",
                "    \n",
                "    # Distribui√ß√£o dos scores\n",
                '    fig = make_subplots(rows=1, cols=2, subplot_titles=["Distribui√ß√£o de Scores Individual", "Distribui√ß√£o de Diferen√ßas"])\n',
                "    \n",
                "    fig.add_trace(\n",
                "        go.Histogram(\n",
                '            x=df_evaluations["score_colaborador"], \n',
                "            nbinsx=20, \n",
                "            marker_color=COLORS[0],\n",
                '            name="Score Individual"\n',
                "        ),\n",
                "        row=1, col=1\n",
                "    )\n",
                "    \n",
                "    fig.add_trace(\n",
                "        go.Histogram(\n",
                '            x=df_evaluations["diferenca"], \n',
                "            nbinsx=20, \n",
                "            marker_color=COLORS[1],\n",
                '            name="Diferen√ßa vs Grupo"\n',
                "        ),\n",
                "        row=1, col=2\n",
                "    )\n",
                "    \n",
                "    fig.update_layout(\n",
                "        height=400,\n",
                '        title_text="Distribui√ß√£o de Scores e Diferen√ßas",\n',
                "        showlegend=True\n",
                "    )\n",
                "    \n",
                "    fig.show()\n",
                "    \n",
                "    # Criar dataframe com m√©dias das distribui√ß√µes por pessoa\n",
                '    people = df_evaluations["pessoa"].unique()\n',
                "    dist_data = []\n",
                "    \n",
                "    for person in people:\n",
                '        person_data = df_evaluations[df_evaluations["pessoa"] == person]\n',
                "        \n",
                "        # Verificar se temos colunas de frequ√™ncia\n",
                '        if "freq_colab_pct" in person_data.columns:\n',
                "            # Agregar porcentagens m√©dias para cada categoria\n",
                '            avg_colab = np.mean(np.stack(person_data["freq_colab_pct"].values), axis=0)\n',
                "            \n",
                "            for i, lbl in enumerate(position_labels):\n",
                "                dist_data.append({\n",
                '                    "pessoa": person,\n',
                '                    "categoria": lbl,\n',
                '                    "porcentagem": avg_colab[i],\n',
                '                    "ordem": i\n',
                "                })\n",
                "    \n",
                "    if dist_data:\n",
                "        df_dist = pd.DataFrame(dist_data)\n",
                "        \n",
                "        # Visualizar distribui√ß√£o por pessoa\n",
                "        fig = px.bar(\n",
                "            df_dist,\n",
                '            x="pessoa", \n',
                '            y="porcentagem",\n',
                '            color="categoria",\n',
                '            barmode="stack",\n',
                '            category_orders={"categoria": position_labels},\n',
                "            color_discrete_sequence=px.colors.qualitative.Plotly,\n",
                '            title="Distribui√ß√£o de Avalia√ß√µes por Pessoa",\n',
                "            labels={\n",
                '                "pessoa": "Pessoa",\n',
                '                "porcentagem": "Porcentagem (%)",\n',
                '                "categoria": "Categoria de Avalia√ß√£o"\n',
                "            }\n",
                "        )\n",
                "        \n",
                "        fig.update_layout(\n",
                "            height=500,\n",
                '            yaxis_title="Porcentagem (%)",\n',
                "            yaxis_range=[0, 100],\n",
                '            legend_title_text="Categoria"\n',
                "        )\n",
                "        \n",
                "        fig.show()\n",
                "    ",
            ],
        },
    ]

    # Add report cells
    report_cells = [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üßÆ An√°lise por Pessoa\n",
                "Compara√ß√£o de desempenho entre diferentes pessoas avaliadas.",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "if not df_evaluations.empty:\n",
                "    # Scores m√©dios por pessoa\n",
                '    person_scores = df_evaluations.groupby("pessoa").agg(\n',
                '        score_medio=("score_colaborador", "mean"),\n',
                '        diferenca_media=("diferenca", "mean"),\n',
                '        score_minimo=("score_colaborador", "min"),\n',
                '        score_maximo=("score_colaborador", "max"),\n',
                '        contagem=("score_colaborador", "count")\n',
                "    ).reset_index()\n",
                "    \n",
                "    # Plotar gr√°fico de barras comparativo\n",
                "    fig = px.bar(\n",
                "        person_scores,\n",
                '        x="pessoa",\n',
                '        y="score_medio",\n',
                '        error_y=person_scores["score_maximo"] - person_scores["score_medio"],\n',
                '        error_y_minus=person_scores["score_medio"] - person_scores["score_minimo"],\n',
                '        color="diferenca_media",\n',
                '        size="contagem",\n',
                '        hover_data=["score_minimo", "score_maximo", "contagem"],\n',
                "        color_continuous_scale=px.colors.diverging.RdBu,\n",
                "        color_continuous_midpoint=0,\n",
                '        title="Score M√©dio por Pessoa (com barras de erro min-max)",\n',
                "        labels={\n",
                '            "pessoa": "Pessoa",\n',
                '            "score_medio": "Score M√©dio",\n',
                '            "diferenca_media": "Diferen√ßa vs Grupo",\n',
                '            "score_minimo": "Score M√≠nimo",\n',
                '            "score_maximo": "Score M√°ximo",\n',
                '            "contagem": "Quantidade de Avalia√ß√µes"\n',
                "        }\n",
                "    )\n",
                "    \n",
                "    fig.update_layout(\n",
                "        height=500,\n",
                '        xaxis_title="Pessoa",\n',
                '        yaxis_title="Score M√©dio",\n',
                '        coloraxis_colorbar=dict(title="Diferen√ßa vs Grupo")\n',
                "    )\n",
                "    \n",
                "    fig.show()\n",
            ],
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìã Recomenda√ß√µes e A√ß√µes\n",
                "Principais insights e recomenda√ß√µes baseadas nos dados.",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "if not df_evaluations.empty:\n",
                "    # Gerar relat√≥rios por pessoa\n",
                '    for person in df_evaluations["pessoa"].unique():\n',
                '        person_data = df_evaluations[df_evaluations["pessoa"] == person]\n',
                '        person_behaviors = person_data.groupby(["direcionador", "comportamento"]).agg(\n',
                '            score=("score_colaborador", "mean"),\n',
                '            diferenca=("diferenca", "mean")\n',
                "        ).reset_index()\n",
                "        \n",
                "        if not person_behaviors.empty:\n",
                "            # Top strength\n",
                '            top = person_behaviors.sort_values("score", ascending=False).iloc[0]\n',
                "            # Area for improvement\n",
                '            bottom = person_behaviors.sort_values("score").iloc[0]\n',
                "            \n",
                '            html_person = f"""\n',
                '            <div class="alert-success">\n',
                "            <h3>Sugest√µes para {person}</h3>\n",
                '            <p><strong>Ponto forte a alavancar:</strong> {top["direcionador"]} - {top["comportamento"]} ({top["score"]:.2f})</p>\n',
                '            <p><strong>√Årea para desenvolvimento:</strong> {bottom["direcionador"]} - {bottom["comportamento"]} ({bottom["score"]:.2f})</p>\n',
                "            <p><strong>Recomenda√ß√µes:</strong></p>\n",
                "            <ol>\n",
                '            <li>Continuar demonstrando forte desempenho em {top["direcionador"]}, especialmente em {top["comportamento"]}.</li>\n',
                '            <li>Desenvolver um plano de a√ß√£o para melhorar {bottom["direcionador"]}, com foco em {bottom["comportamento"]}.</li>\n',
                "            <li>Buscar feedback cont√≠nuo e estabelecer m√©tricas claras para acompanhar o progresso.</li>\n",
                "            </ol>\n",
                "            </div>\n",
                '            """\n',
                "            \n",
                "            display(HTML(html_person))\n",
            ],
        },
    ]

    # Add all cells to notebook
    notebook["cells"].extend(data_loading_cells)
    notebook["cells"].extend(corrected_analysis_cells)
    notebook["cells"].extend(visualization_cells)
    notebook["cells"].extend(report_cells)

    # Create output directory if it doesn't exist
    output_dir = os.path.dirname(output_path)
    if output_dir and not os.path.exists(output_dir):
        os.makedirs(output_dir)

    # Save notebook
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(notebook, f, indent=1)

    print(f"Notebook criado com sucesso em: {output_path}")
    return output_path


if __name__ == "__main__":
    create_people_analytics_notebook("analyze_people_data.ipynb")
