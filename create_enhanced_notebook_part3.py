import json

# Carregar notebook base
with open('analyze_people_data_enhanced.ipynb', 'r', encoding='utf-8') as f:
    notebook = json.load(f)

# Corrigir a fun√ß√£o de convers√£o para considerar o vetor de 6 posi√ß√µes corretamente
conversion_fix_cells = [
  {
   'cell_type': 'markdown',
   'metadata': {},
   'source': ['## ‚ö†Ô∏è Corre√ß√£o Importante na Interpreta√ß√£o dos Dados\n', 
              'Os vetores de frequ√™ncia t√™m 6 posi√ß√µes com significados espec√≠ficos.']
  },
  {
   'cell_type': 'code',
   'execution_count': None,
   'metadata': {},
   'outputs': [],
   'source': [
                'def convert_evaluation_to_dataframe_corrected(eval_data, person, year):\n',
                '    """Converte dados de avalia√ß√£o para DataFrame com interpreta√ß√£o correta dos vetores\n',
                '    \n',
                '    Args:\n',
                '        eval_data (dict): Dados de avalia√ß√£o\n',
                '        person (str): Nome da pessoa\n',
                '        year (str): Ano da avalia√ß√£o\n',
                '        \n',
                '    Returns:\n',
                '        pandas.DataFrame: DataFrame com os dados estruturados corretamente\n',
                '    """\n',
                '    rows = []\n',
                '    \n',
                '    # R√≥tulos para cada posi√ß√£o no vetor\n',
                '    position_labels = ["n√£o informado", "refer√™ncia", "acima do esperado", \n',
                '                      "dentro do esperado", "abaixo do esperado", "muito abaixo do esperado"]\n',
                '    \n',
                '    # Valores para c√°lculo do score (invertido para que "acima do esperado" tenha maior valor)\n',
                '    # N√£o informado recebe 0, refer√™ncia √© neutro, e os outros s√£o por escala de valor\n',
                '    position_values = [0, 2.5, 4, 3, 2, 1]\n',
                '    \n',
                '    try:\n',
                '        for direcionador in eval_data["data"]["direcionadores"]:\n',
                '            for comportamento in direcionador.get("comportamentos", []):\n',
                '                for avaliacao in comportamento.get("avaliacoes_grupo", []):\n',
                '                    freq_colab = avaliacao.get("frequencia_colaborador", [])\n',
                '                    freq_grupo = avaliacao.get("frequencia_grupo", [])\n',
                '                    \n',
                '                    # Verificar se temos vetores v√°lidos com 6 posi√ß√µes\n',
                '                    if len(freq_colab) != 6 or len(freq_grupo) != 6 or sum(freq_colab) == 0 or sum(freq_grupo) == 0:\n',
                '                        continue\n',
                '                    \n',
                '                    # Calcular scores ponderados pelos valores de cada posi√ß√£o\n',
                '                    # Exclu√≠mos "n√£o informado" do c√°lculo do total para n√£o distorcer\n',
                '                    total_colab = sum(freq_colab[1:]) # Excluindo posi√ß√£o 0 (n√£o informado)\n',
                '                    total_grupo = sum(freq_grupo[1:]) # Excluindo posi√ß√£o 0 (n√£o informado)\n',
                '                    \n',
                '                    if total_colab == 0 or total_grupo == 0:\n',
                '                        continue\n',
                '                    \n',
                '                    # C√°lculo do score ponderado\n',
                '                    score_colab = sum(v * position_values[i] for i, v in enumerate(freq_colab)) / total_colab\n',
                '                    score_grupo = sum(v * position_values[i] for i, v in enumerate(freq_grupo)) / total_grupo\n',
                '                    \n',
                '                    # Criar distribui√ß√£o percentual para visualiza√ß√£o\n',
                '                    dist_colab = [round(100 * v / sum(freq_colab), 1) if sum(freq_colab) > 0 else 0 for v in freq_colab]\n',
                '                    dist_grupo = [round(100 * v / sum(freq_grupo), 1) if sum(freq_grupo) > 0 else 0 for v in freq_grupo]\n',
                '                    \n',
                '                    row = {\n',
                '                        "pessoa": person,\n',
                '                        "ano": year,\n',
                '                        "direcionador": direcionador.get("direcionador", ""),\n',
                '                        "comportamento": comportamento.get("comportamento", ""),\n',
                '                        "avaliador": avaliacao.get("avaliador", ""),\n',
                '                        "score_colaborador": score_colab,\n',
                '                        "score_grupo": score_grupo,\n',
                '                        "diferenca": score_colab - score_grupo,\n',
                '                        "freq_colab_raw": freq_colab,\n',
                '                        "freq_grupo_raw": freq_grupo,\n',
                '                        "freq_colab_pct": dist_colab,\n',
                '                        "freq_grupo_pct": dist_grupo\n',
                '                    }\n',
                '                    rows.append(row)\n',
                '    except Exception as e:\n',
                '        print(f"Erro ao processar dados para {person}, {year}: {str(e)}")\n',
                '    \n',
                '    return pd.DataFrame(rows)\n',
                '\n',
                'def load_all_evaluations_corrected(data_dir):\n',
                '    """Carrega todas as avalia√ß√µes com interpreta√ß√£o correta dos vetores\n',
                '    \n',
                '    Args:\n',
                '        data_dir (str): Caminho do diret√≥rio com os dados\n',
                '        \n',
                '    Returns:\n',
                '        pandas.DataFrame: DataFrame consolidado com todos os dados\n',
                '    """\n',
                '    files = scan_directory(data_dir, "*/*/resultado.json")\n',
                '    all_data = []\n',
                '    \n',
                '    for file_path in files:\n',
                '        diagnosis = diagnose_json_file(file_path)\n',
                '        if diagnosis["status"] == "error" or diagnosis["status"] == "issues":\n',
                '            print(f"Problemas com arquivo {file_path}: {diagnosis.get(\'message\') or diagnosis.get(\'issues\')}")\n',
                '            continue\n',
                '            \n',
                '        person, year = extract_person_year(file_path)\n',
                '        df = convert_evaluation_to_dataframe_corrected(diagnosis["data"], person, year)\n',
                '        all_data.append(df)\n',
                '    \n',
                '    if not all_data:\n',
                '        return pd.DataFrame()\n',
                '        \n',
                '    return pd.concat(all_data, ignore_index=True)\n',
                '\n',
                '# Carregar dados com m√©todo corrigido\n',
                'position_labels = ["N√£o informado", "Refer√™ncia", "Acima do esperado", "Dentro do esperado", "Abaixo do esperado", "Muito abaixo do esperado"]\n',
                'df_corrected = load_all_evaluations_corrected(DATA_DIR)\n',
                '\n',
                'if df_corrected.empty:\n',
                '    display(HTML(\'<div class="alert-danger">Nenhum dado de avalia√ß√£o encontrado com o m√©todo corrigido.</div>\'))\n',
                'else:\n',
                '    display(HTML(f\'<div class="alert-success">Dados carregados corretamente com nova interpreta√ß√£o dos vetores de frequ√™ncia!</div>\'))\n',
                '    display(df_corrected.head())\n'
               ]
  },
  {
   'cell_type': 'markdown',
   'metadata': {},
   'source': ['## üìä Visualiza√ß√£o da Distribui√ß√£o de Frequ√™ncias\n', 
              'An√°lise da distribui√ß√£o percentual em cada categoria de avalia√ß√£o.']
  },
  {
   'cell_type': 'code',
   'execution_count': None,
   'metadata': {},
   'outputs': [],
   'source': ['if not df_corrected.empty:\n',
                '    # Criar dataframe com m√©dias das distribui√ß√µes por pessoa\n',
                '    people = df_corrected["pessoa"].unique()\n',
                '    dist_data = []\n',
                '    \n',
                '    for person in people:\n',
                '        person_data = df_corrected[df_corrected["pessoa"] == person]\n',
                '        \n',
                '        # Agregar porcentagens m√©dias para cada categoria\n',
                '        avg_colab = np.mean(np.stack(person_data["freq_colab_pct"].values), axis=0)\n',
                '        \n',
                '        for i, lbl in enumerate(position_labels):\n',
                '            dist_data.append({\n',
                '                "pessoa": person,\n',
                '                "categoria": lbl,\n',
                '                "porcentagem": avg_colab[i],\n',
                '                "ordem": i\n',
                '            })\n',
                '    \n',
                '    df_dist = pd.DataFrame(dist_data)\n',
                '    \n',
                '    # Visualizar distribui√ß√£o por pessoa\n',
                '    fig = px.bar(\n',
                '        df_dist,\n',
                '        x="pessoa", \n',
                '        y="porcentagem",\n',
                '        color="categoria",\n',
                '        barmode="stack",\n',
                '        category_orders={"categoria": position_labels},\n',
                '        color_discrete_sequence=px.colors.qualitative.Plotly,\n',
                '        title="Distribui√ß√£o de Avalia√ß√µes por Pessoa",\n',
                '        labels={\n',
                '            "pessoa": "Pessoa",\n',
                '            "porcentagem": "Porcentagem (%)",\n',
                '            "categoria": "Categoria de Avalia√ß√£o"\n',
                '        }\n',
                '    )\n',
                '    \n',
                '    fig.update_layout(\n',
                '        height=500,\n',
                '        yaxis_title="Porcentagem (%)",\n',
                '        yaxis_range=[0, 100],\n',
                '        legend_title_text="Categoria"\n',
                '    )\n',
                '    \n',
                '    fig.show()\n',
                '    \n',
                '    # Criar um heatmap da distribui√ß√£o m√©dia por pessoa\n',
                '    pivot_data = df_dist.pivot_table(\n',
                '        index="pessoa",\n',
                '        columns="categoria",\n',
                '        values="porcentagem",\n',
                '        aggfunc="mean"\n',
                '    )\n',
                '    \n',
                '    # Reordenar as colunas para a ordem correta das categorias\n',
                '    pivot_data = pivot_data[position_labels]\n',
                '    \n',
                '    fig = px.imshow(\n',
                '        pivot_data,\n',
                '        text_auto=".1f",\n',
                '        aspect="auto",\n',
                '        color_continuous_scale="RdBu_r",\n',
                '        title="Heatmap da Distribui√ß√£o de Avalia√ß√µes (%)",\n',
                '        labels={\n',
                '            "x": "Categoria",\n',
                '            "y": "Pessoa",\n',
                '            "color": "Porcentagem (%)"\n',
                '        }\n',
                '    )\n',
                '    \n',
                '    fig.update_layout(\n',
                '        height=400,\n',
                '        margin=dict(l=50, r=50, t=80, b=50)\n',
                '    )\n',
                '    \n',
                '    fig.show()\n'
               ]
  },
  {
   'cell_type': 'markdown',
   'metadata': {},
   'source': ['## üìà Scores Corrigidos\n', 
              'An√°lise dos scores recalculados com a interpreta√ß√£o correta dos vetores.']
  },
  {
   'cell_type': 'code',
   'execution_count': None,
   'metadata': {},
   'outputs': [],
   'source': ['if not df_corrected.empty:\n',
                '    # Comparar scores com m√©todo correto vs anterior\n',
                '    person_scores_corrected = df_corrected.groupby("pessoa").agg(\n',
                '        score_medio=("score_colaborador", "mean"),\n',
                '        diferenca_media=("diferenca", "mean"),\n',
                '        score_minimo=("score_colaborador", "min"),\n',
                '        score_maximo=("score_colaborador", "max"),\n',
                '        contagem=("score_colaborador", "count")\n',
                '    ).reset_index()\n',
                '    \n',
                '    # Radar chart por compet√™ncia\n',
                '    competency_scores = df_corrected.groupby(["pessoa", "direcionador"]).agg(\n',
                '        score_medio=("score_colaborador", "mean")\n',
                '    ).reset_index()\n',
                '    \n',
                '    # Criar um radar chart para cada pessoa\n',
                '    fig = go.Figure()\n',
                '    \n',
                '    for person in competency_scores["pessoa"].unique():\n',
                '        person_data = competency_scores[competency_scores["pessoa"] == person]\n',
                '        \n',
                '        fig.add_trace(go.Scatterpolar(\n',
                '            r=person_data["score_medio"],\n',
                '            theta=person_data["direcionador"],\n',
                '            fill="toself",\n',
                '            name=person\n',
                '        ))\n',
                '    \n',
                '    fig.update_layout(\n',
                '        polar=dict(\n',
                '            radialaxis=dict(\n',
                '                visible=True,\n',
                '                range=[0, 4]\n',
                '            )\n',
                '        ),\n',
                '        title="Radar Chart de Compet√™ncias por Pessoa",\n',
                '        height=600,\n',
                '        showlegend=True\n',
                '    )\n',
                '    \n',
                '    fig.show()\n',
                '    \n',
                '    # Tabela de scores por direcionador e comportamento\n',
                '    behavior_scores = df_corrected.groupby(["direcionador", "comportamento"]).agg(\n',
                '        score_medio=("score_colaborador", "mean"),\n',
                '        diferenca_media=("diferenca", "mean"),\n',
                '        contagem=("score_colaborador", "count")\n',
                '    ).reset_index().sort_values(["direcionador", "score_medio"], ascending=[True, False])\n',
                '    \n',
                '    display(behavior_scores.style\n',
                '           .format({"score_medio": "{:.2f}", "diferenca_media": "{:.2f}"})\n',
                '           .background_gradient(cmap="RdYlGn", subset=["score_medio"])\n',
                '           .background_gradient(cmap="RdBu", subset=["diferenca_media"]))\n'
               ]
  },
  {
   'cell_type': 'markdown',
   'metadata': {},
   'source': ['## üìã Recomenda√ß√µes e A√ß√µes\n', 
              'Principais insights e recomenda√ß√µes baseadas nos dados corrigidos.']
  },
  {
   'cell_type': 'code',
   'execution_count': None,
   'metadata': {},
   'outputs': [],
   'source': ['if not df_corrected.empty:\n',
                '    # Identificar pontos fortes e oportunidades de melhoria\n',
                '    html_insights = """\n',
                '    <div class="alert-info">\n',
                '    <h3>Insights Principais</h3>\n',
                '    <p>Com base na interpreta√ß√£o correta dos vetores de frequ√™ncia, identificamos:</p>\n',
                '    <ul>\n',
                '    """\n',
                '    \n',
                '    # Top compet√™ncias\n',
                '    top_comp = behavior_scores.sort_values("score_medio", ascending=False).iloc[0]\n',
                '    html_insights += f"<li><strong>Compet√™ncia mais forte:</strong> {top_comp[\"direcionador\"]} - {top_comp[\"comportamento\"]} ({top_comp[\"score_medio\"]:.2f}/4.0)</li>"\n',
                '    \n',
                '    # Compet√™ncias para desenvolvimento\n',
                '    bottom_comp = behavior_scores.sort_values("score_medio").iloc[0]\n',
                '    html_insights += f"<li><strong>Oportunidade de desenvolvimento:</strong> {bottom_comp[\"direcionador\"]} - {bottom_comp[\"comportamento\"]} ({bottom_comp[\"score_medio\"]:.2f}/4.0)</li>"\n',
                '    \n',
                '    # Maiores gaps vs grupo\n',
                '    if behavior_scores["diferenca_media"].min() < -0.5:\n',
                '        gap_comp = behavior_scores.sort_values("diferenca_media").iloc[0]\n',
                '        html_insights += f"<li><strong>Maior gap vs. grupo:</strong> {gap_comp[\"direcionador\"]} - {gap_comp[\"comportamento\"]} ({gap_comp[\"diferenca_media\"]:.2f})</li>"\n',
                '    \n',
                '    html_insights += """\n',
                '    </ul>\n',
                '    </div>\n',
                '    """\n',
                '    \n',
                '    display(HTML(html_insights))\n',
                '    \n',
                '    # Sugest√µes de a√ß√£o por pessoa\n',
                '    for person in df_corrected["pessoa"].unique():\n',
                '        person_data = df_corrected[df_corrected["pessoa"] == person]\n',
                '        person_behaviors = person_data.groupby(["direcionador", "comportamento"]).agg(\n',
                '            score=("score_colaborador", "mean"),\n',
                '            diferenca=("diferenca", "mean")\n',
                '        ).reset_index()\n',
                '        \n',
                '        # Top strength\n',
                '        top = person_behaviors.sort_values("score", ascending=False).iloc[0]\n',
                '        # Area for improvement\n',
                '        bottom = person_behaviors.sort_values("score").iloc[0]\n',
                '        \n',
                '        html_person = f"""\n',
                '        <div class="alert-success">\n',
                '        <h3>Sugest√µes para {person}</h3>\n',
                '        <p><strong>Ponto forte a alavancar:</strong> {top[\"direcionador\"]} - {top[\"comportamento\"]} ({top[\"score\"]:.2f}/4.0)</p>\n',
                '        <p><strong>√Årea para desenvolvimento:</strong> {bottom[\"direcionador\"]} - {bottom[\"comportamento\"]} ({bottom[\"score\"]:.2f}/4.0)</p>\n',
                '        <p><strong>Recomenda√ß√µes:</strong></p>\n',
                '        <ol>\n',
                '        <li>Continuar demonstrando forte desempenho em {top[\"direcionador\"]}, especialmente em {top[\"comportamento\"]}.</li>\n',
                '        <li>Desenvolver um plano de a√ß√£o para melhorar {bottom[\"direcionador\"]}, com foco em {bottom[\"comportamento\"]}.</li>\n',
                '        <li>Buscar feedback cont√≠nuo e estabelecer m√©tricas claras para acompanhar o progresso.</li>\n',
                '        </ol>\n',
                '        </div>\n',
                '        """\n',
                '        \n',
                '        display(HTML(html_person))\n'
               ]
  }
]

# Adicionar as c√©lulas ao notebook
for cell in conversion_fix_cells:
    notebook['cells'].append(cell)

# Salvar notebook atualizado
with open('analyze_people_data_enhanced_complete.ipynb', 'w', encoding='utf-8') as f:
    json.dump(notebook, f, indent=1)

print('Notebook completo com interpreta√ß√£o corrigida dos dados criado com sucesso!') 